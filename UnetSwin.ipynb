{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd, ScaleIntensityRanged, CropForegroundd,\n",
    "    RandCropByPosNegLabeld, RandFlipd, RandRotate90d, RandShiftIntensityd, EnsureTyped, EnsureType, DivisiblePadd\n",
    ")\n",
    "from monai.data import DataLoader, CacheDataset\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.losses import DiceLoss\n",
    "from monai.utils import set_determinism\n",
    "from monai.data import decollate_batch\n",
    "from monai.transforms import DivisiblePad\n",
    "from monai.data.image_reader import NibabelReader\n",
    "import pty\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pty.fork = lambda: (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::RuntimeWarning'\n",
    "\n",
    "\n",
    "# Set deterministic training for reproducibility\n",
    "set_determinism(seed=0)\n",
    "\n",
    "# modality_keys = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "# 'dataset/MICCAI_BraTS2020_TrainingData'\n",
    "# Define directories\n",
    "train_path = 'dataset/MICCAI_BraTS2020_TrainingData/'\n",
    "val_path = 'dataset/MICCAI_BraTS2020_ValidationData/'\n",
    "# modality_keys = [\"flair\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a list of data dictionaries\n",
    "def create_data_list(data_dir):\n",
    "    data_list = []\n",
    "    patients = os.listdir(data_dir)\n",
    "    for patient in patients:\n",
    "        patient_dir = os.path.join(data_dir, patient)\n",
    "        if os.path.isdir(patient_dir):\n",
    "            data_dict = {\n",
    "                \"flair\": os.path.join(patient_dir, f\"{patient}_flair.nii\"),\n",
    "                \"t1\": os.path.join(patient_dir, f\"{patient}_t1.nii\"),\n",
    "                \"t1ce\": os.path.join(patient_dir, f\"{patient}_t1ce.nii\"),\n",
    "                \"t2\": os.path.join(patient_dir, f\"{patient}_t2.nii\")\n",
    "            }\n",
    "            data_list.append(data_dict)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = create_data_list(train_path)\n",
    "val_data_list = create_data_list(val_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], reader=NibabelReader()),\n",
    "        EnsureChannelFirstd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"]),\n",
    "        Spacingd(\n",
    "            keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"],\n",
    "            pixdim=(2.0, 2.0, 2.0),  # Adjust pixdim to a slightly larger value\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        Orientationd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], a_min=-175, a_max=250,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], source_key=\"flair\", allow_smaller=True),  # Explicitly set allow_smaller\n",
    "        DivisiblePadd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], k=32),  # Padding to make dimensions divisible by 32\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"],\n",
    "            label_key=\"flair\",\n",
    "            spatial_size=(64, 64, 64),  # Adjust the spatial size as needed\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=1,\n",
    "            image_key=\"flair\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], prob=0.5, spatial_axis=2),\n",
    "        RandRotate90d(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], prob=0.5, max_k=3),\n",
    "        RandShiftIntensityd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], offsets=0.10, prob=0.5),\n",
    "        EnsureTyped(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 369/369 [05:43<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_ds = CacheDataset(\n",
    "    data=train_data_list,\n",
    "    transform=train_transforms,\n",
    "#     cache_rate=0.5,\n",
    "#     num_workers=4,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size= 1, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], reader=NibabelReader()),\n",
    "        EnsureChannelFirstd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"]),\n",
    "        Spacingd(\n",
    "            keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"],\n",
    "            pixdim=(2.0, 2.0, 2.0),  # Adjust pixdim to a slightly larger value\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        Orientationd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], a_min=-175, a_max=250,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], source_key=\"flair\", allow_smaller=True),  # Explicitly set allow_smaller\n",
    "        DivisiblePadd(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"], k=32),  # Padding to make dimensions divisible by 32\n",
    "        EnsureTyped(keys=[\"flair\", \"t1\", \"t1ce\", \"t2\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 125/125 [02:55<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_ds = CacheDataset(\n",
    "    data=val_data_list,\n",
    "    transform=val_transforms,\n",
    "#     cache_rate=0.5,\n",
    "#     num_workers=4,\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size= 1, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "# Define model, loss, optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SwinUNETR(\n",
    "    img_size=(64, 64, 64),  # Adjust image size accordingly\n",
    "    in_channels=4,\n",
    "    out_channels=4,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.MSELoss()  # Mean Squared Error Loss for reconstruction\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 average loss: 0.0231\n",
      "----------\n",
      "epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 average loss: 0.0058\n",
      "----------\n",
      "epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 average loss: 0.0040\n",
      "----------\n",
      "epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 average loss: 0.0030\n",
      "----------\n",
      "epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 average loss: 0.0026\n",
      "----------\n",
      "epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 average loss: 0.0024\n",
      "----------\n",
      "epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 average loss: 0.0020\n",
      "----------\n",
      "epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 average loss: 0.0014\n",
      "----------\n",
      "epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 average loss: 0.0012\n",
      "----------\n",
      "epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m1/23CS60R48/.local/lib/python3.8/site-packages/monai/transforms/utils.py:606: UserWarning: Num foregrounds 1123200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 average loss: 0.0012\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "max_epochs = 10\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs = torch.cat([batch_data[\"flair\"], batch_data[\"t1\"], batch_data[\"t1ce\"], batch_data[\"t2\"]], dim=1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        # print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_saved/swin_unetr_reconstruction.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model state dictionary to a file\n",
    "model_save_path = \"model_saved/swin_unetr_reconstruction.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from saved state dictionary\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the saved state dictionary\n",
    "loaded_model = SwinUNETR(\n",
    "    img_size=(128, 128, 128),\n",
    "    in_channels=4,  # 4 modalities as input\n",
    "    out_channels=4,  # 4 modalities as output for reconstruction\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n",
    "loaded_model.load_state_dict(torch.load(model_save_path))\n",
    "print(\"Model loaded from saved state dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Mean Squared Error: 0.000937357866205275\n"
     ]
    }
   ],
   "source": [
    "# Define a simple evaluation loop and calculate accuracy (MSE in this case)\n",
    "mse_values = []\n",
    "with torch.no_grad():\n",
    "    for val_data in val_loader:\n",
    "        val_images = torch.cat([val_data[\"flair\"], val_data[\"t1\"], val_data[\"t1ce\"], val_data[\"t2\"]], dim=1).to(device)\n",
    "        val_outputs = loaded_model(val_images)\n",
    "        \n",
    "        # Calculate MSE for each sample and store the value\n",
    "        mse_value = mean_squared_error(val_images.cpu().numpy().flatten(), val_outputs.cpu().numpy().flatten())\n",
    "        mse_values.append(mse_value)\n",
    "\n",
    "# Calculate and print the average MSE\n",
    "average_mse = sum(mse_values) / len(mse_values)\n",
    "print(f\"Validation Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_saved/4_modality_swin_unetr_reconstruction.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model state dictionary to a file\n",
    "model_save_path = \"model_saved/4_modality_swin_unetr_reconstruction.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
