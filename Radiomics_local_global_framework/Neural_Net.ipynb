{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "import csv\n",
    "from sklearn.linear_model import LassoCV\n",
    "from stg import STG\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used = 'Neural_Network'\n",
    "print_interval = 5000\n",
    "epochs = 10000\n",
    "selection_method = 'Stochastic Gates'\n",
    "# selection_method = 'lasso'\n",
    "\n",
    "Light_GBM_global = [\n",
    "    # \"flair_t1ce_t2\",\n",
    "    # \"flair_t1ce_t2\",\n",
    "    # \"flair\",\n",
    "    # \"flair_t1ce\",\n",
    "    \"flair_t1ce\"\n",
    "]\n",
    "Light_GBM_local = [\n",
    "    # \"flair_t1ce_t2\",\n",
    "    # \"flair_t1ce\",\n",
    "    # \"flair\",\n",
    "    # \"t2\",\n",
    "    \"flair_t1ce\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(filepath):\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_radiomic_fetures(target_directory, file_name):\n",
    "    # Load the numpy array from the file in the target directory\n",
    "    file_path = os.path.join(target_directory, file_name)\n",
    "    array = np.load(file_path)\n",
    "    print(f\"Array loaded from '{file_path}'\")\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_parameters(modality_used,  model_class):\n",
    "    model_dir = f\"./models/{selection_method}_feature_selection/{model_used}/{modality_used}/\"\n",
    "    \n",
    "    model_file = os.path.join(model_dir, 'model.pt')\n",
    "    params_file = os.path.join(model_dir, 'params.txt')\n",
    "    mask_file = os.path.join(model_dir, f'{selection_method}_mask.npy')\n",
    "    # Load the selected features mask\n",
    "    mask = np.load(mask_file)\n",
    "    inputdim = np.count_nonzero(mask)\n",
    "    # Load the model\n",
    "    model = model_class(inputdim)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Load the parameters\n",
    "    with open(params_file, 'r') as file:\n",
    "        params = file.read().strip()\n",
    "    \n",
    "    \n",
    "    print(f\"Model, parameters, and {selection_method} mask loaded successfully for modality {modality_used}.\")\n",
    "    \n",
    "    return model, params, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_parameters(model, modality_used, mask, params):\n",
    "    model_dir = f\"./models/{selection_method}_feature_selection/{model_used}_256_dim/{modality_used}/Intersection_mask_1_2/\"\n",
    "    ensure_directory_exists(model_dir)\n",
    "    model_file = os.path.join(model_dir, 'model.pt')\n",
    "    params_file = os.path.join(model_dir, 'params.txt')\n",
    "    mask_file = os.path.join(model_dir, f'{selection_method}_mask.npy')\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    \n",
    "    # Save the parameters\n",
    "    with open(params_file, 'w') as file:\n",
    "        file.write(f\"Best parameters: {params}\\n\")\n",
    "    \n",
    "    # Save the selected features mask\n",
    "    np.save(mask_file, mask)\n",
    "    \n",
    "    print(f\"Model, parameters, and {selection_method} mask saved successfully for modality {modality_used}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine_features(modality_keys, dataset_type):\n",
    "    combined_features = []\n",
    "    for modality in modality_keys:\n",
    "        # Load the features for each modality\n",
    "        features = np.load(f'../local_spatial_Framework/features/{modality}/{dataset_type}/{dataset_type}_backbone_outputs.npy')\n",
    "        combined_features.append(features)\n",
    "    # Combine features along the feature dimension (axis=1)\n",
    "    return np.concatenate(combined_features, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_csv(y_pred_validation, modality_used):\n",
    "    df = pd.read_csv('../dataset/MICCAI_BraTS2020_ValidationData/survival_evaluation.csv')\n",
    "    validation_ids = df['BraTS20ID'].values\n",
    "    \n",
    "    #removing 116 paitents ID from list\n",
    "    validation_ids = np.delete(validation_ids, 26, axis=0)\n",
    "    \n",
    "    filename = f\"../radiomics_local_global_predictions/{selection_method}_feture_selection/{model_used}_256_dim/Intersection_mask_1_2/{modality_used}_{model_used}.csv\"\n",
    "\n",
    "    ensure_directory_exists(filename)\n",
    "\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"ID\", \"Days\"])\n",
    "        for id, day in zip(validation_ids, y_pred_validation):\n",
    "            writer.writerow([id, day])\n",
    "\n",
    "    print(f\"CSV file '{filename}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(modality_used):\n",
    "    base_dir = os.path.join('../Global_extracted_features', modality_used)\n",
    "    train_features = np.load(os.path.join(base_dir, 'train_features.npy'))\n",
    "    validate_features = np.load(os.path.join(base_dir, 'validate_features.npy'))\n",
    "    train_labels = np.load(os.path.join(base_dir, 'train_labels.npy'))\n",
    "    return train_features, validate_features, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1st model\n",
    "# class SimpleNN_1(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SimpleNN_1, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 200)\n",
    "#         self.fc2 = nn.Linear(200, 50)\n",
    "#         self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2nd model\n",
    "# class SimpleNN(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SimpleNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 128)\n",
    "#         self.fc2 = nn.Linear(128, 64)\n",
    "#         self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(train_features, test_features, train_labels, modality_used):\n",
    "    scaler = StandardScaler()\n",
    "    train_features_scaled = scaler.fit_transform(train_features)\n",
    "    test_features_scaled = scaler.transform(test_features)\n",
    "    \n",
    "    # Print feature size before Lasso feature selection\n",
    "    # print(f\"Size of features before Lasso: {train_features_scaled.shape}\")\n",
    "\n",
    "    # # Lasso Feature Selection with increased regularization\n",
    "    # lasso = LassoCV(cv=5, random_state=42, max_iter=100, alphas=np.logspace(-4, -0.5, 30)).fit(train_features_scaled, train_labels)\n",
    "    \n",
    "    # # Select non-zero coefficients\n",
    "    # mask = lasso.coef_ != 0\n",
    "    model_dir = f\"./models/{selection_method}_feature_selection/{model_used}/{modality_used}/\"\n",
    "    mask_file = os.path.join(model_dir, f'{selection_method}_mask.npy')\n",
    "    mask = np.load(mask_file)\n",
    "\n",
    "    train_features_selected = train_features_scaled[:, mask]\n",
    "    test_features_selected = test_features_scaled[:, mask]\n",
    "\n",
    "    print(f\"Size of features after lasso Gates: {train_features_selected.shape}\")\n",
    "      \n",
    "    # Split the selected features into training and validation sets\n",
    "    train_features_final, val_features_final, train_labels_final, val_labels_final = train_test_split(\n",
    "        train_features_selected, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert features and labels to PyTorch tensors\n",
    "    train_features_tensor = torch.tensor(train_features_final, dtype=torch.float32).to(device)\n",
    "    train_labels_tensor = torch.tensor(train_labels_final, dtype=torch.float32).view(-1, 1).to(device)\n",
    "    val_features_tensor = torch.tensor(val_features_final, dtype=torch.float32).to(device)\n",
    "    val_labels_tensor = torch.tensor(val_labels_final, dtype=torch.float32).view(-1, 1).to(device)\n",
    "    test_features_tensor = torch.tensor(test_features_selected, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create DataLoader for training data\n",
    "    train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Initialize and train the neural network\n",
    "    input_dim = train_features_selected.shape[1]\n",
    "    model = SimpleNN(input_dim).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_model = None\n",
    "    best_accuracy = float('inf')\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):  # Adjust the number of epochs as needed\n",
    "        epoch_loss = 0\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            print(f'Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader)}')\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_features_tensor)\n",
    "            val_loss = criterion(val_outputs, val_labels_tensor).item()\n",
    "\n",
    "\n",
    "        # Check for the best model\n",
    "        if val_loss < best_accuracy:\n",
    "            best_accuracy = val_loss\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            print(f'Epoch {epoch + 1}, Validation Loss: {val_loss}, best: {best_accuracy}')\n",
    "        model.train()\n",
    "\n",
    "    # Save the best model\n",
    "    model.load_state_dict(best_model)\n",
    "    save_model_and_parameters(model, modality_used, mask, {f\"epochs\": {epochs}, \"lr\": 0.001})\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(test_features_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    make_csv(y_pred_test, modality_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_stochastic_gates(train_features, test_features, train_labels, modality_used, device='cpu', validation_split=0.2):\n",
    "    # Split training data into train and validation sets for STG\n",
    "    train_features_stg, val_features_stg, train_labels_stg, val_labels_stg = train_test_split(\n",
    "        train_features, train_labels, test_size=validation_split, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_features_scaled = scaler.fit_transform(train_features_stg)\n",
    "    val_features_scaled = scaler.transform(val_features_stg)\n",
    "    test_features_scaled = scaler.transform(test_features)\n",
    "    \n",
    "    # Ensure data is in numpy array format\n",
    "    train_features_scaled = np.asarray(train_features_scaled)\n",
    "    val_features_scaled = np.asarray(val_features_scaled)\n",
    "    train_labels_stg = np.asarray(train_labels_stg)\n",
    "    val_labels_stg = np.asarray(val_labels_stg)\n",
    "    test_features_scaled = np.asarray(test_features_scaled)\n",
    "    \n",
    "    print(f\"Size of training features before Stochastic Gates: {train_features_scaled.shape}\")\n",
    "    print(f\"Size of validation features before Stochastic Gates: {val_features_scaled.shape}\")\n",
    "\n",
    "    # # Define and train the STG model\n",
    "    # stg = STG(task_type='regression', input_dim=train_features_scaled.shape[1], output_dim=1,\n",
    "    #           hidden_dims=[100, 50], activation='relu', optimizer='Adam', learning_rate=0.01,\n",
    "    #           batch_size=32, feature_selection=True, device=device)\n",
    "    \n",
    "    # try:\n",
    "    #     # Fit the STG model with train data and validate on the validation set\n",
    "    #     stg.fit(train_features_scaled, train_labels_stg, nr_epochs=10000, verbose=1, print_interval=5000,\n",
    "    #             valid_X=val_features_scaled, valid_y=val_labels_stg)\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error during STG fitting: {str(e)}\")\n",
    "    #     print(f\"Train features shape: {train_features_scaled.shape}\")\n",
    "    #     print(f\"Train labels shape: {train_labels_stg.shape}\")\n",
    "    #     print(f\"Validation features shape: {val_features_scaled.shape}\")\n",
    "    #     print(f\"Validation labels shape: {val_labels_stg.shape}\")\n",
    "    #     return\n",
    "\n",
    "    # Get feature importance scores using get_gates method\n",
    "    # try:\n",
    "    #     importance_scores = stg.get_gates(mode='prob') \n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error getting feature importance: {str(e)}\")\n",
    "    #     print(\"Using all features.\")\n",
    "    #     importance_scores = np.ones(train_features_scaled.shape[1])\n",
    "\n",
    "    # # Select features with importance scores above a threshold\n",
    "    # mask = importance_scores > 0.5  # Adjust threshold as necessary\n",
    "    # t1, t2, mask = load_model_and_parameters(modality_used, SimpleNN_1)\n",
    "    model_dir = f\"./models/{selection_method}_feature_selection/Intersection_mask.npy\"\n",
    "    mask = np.load(model_dir)\n",
    "    \n",
    "    # Apply feature selection to the full training set and test set\n",
    "    train_features_selected = scaler.fit_transform(train_features)[:, mask]\n",
    "    test_features_selected = scaler.transform(test_features)[:, mask]\n",
    "    print(f\"Size of features after Stochastic Gates: {train_features_selected.shape}\")\n",
    "    \n",
    "   # Split the selected features into training and validation sets\n",
    "    train_features_final, val_features_final, train_labels_final, val_labels_final = train_test_split(\n",
    "        train_features_selected, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert features and labels to PyTorch tensors\n",
    "    train_features_tensor = torch.tensor(train_features_final, dtype=torch.float32).to(device)\n",
    "    train_labels_tensor = torch.tensor(train_labels_final, dtype=torch.float32).view(-1, 1).to(device)\n",
    "    val_features_tensor = torch.tensor(val_features_final, dtype=torch.float32).to(device)\n",
    "    val_labels_tensor = torch.tensor(val_labels_final, dtype=torch.float32).view(-1, 1).to(device)\n",
    "    test_features_tensor = torch.tensor(test_features_selected, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create DataLoader for training data\n",
    "    train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Initialize and train the neural network\n",
    "    input_dim = train_features_selected.shape[1]\n",
    "    model = SimpleNN(input_dim).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_model = None\n",
    "    best_accuracy = float('inf')\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):  # Adjust the number of epochs as needed\n",
    "        epoch_loss = 0\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            print(f'Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader)}')\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_features_tensor)\n",
    "            val_loss = criterion(val_outputs, val_labels_tensor).item()\n",
    "\n",
    "\n",
    "        # Check for the best model\n",
    "        if val_loss < best_accuracy:\n",
    "            best_accuracy = val_loss\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            print(f'> Epoch {epoch + 1}, Validation Loss: {val_loss}, best: {best_accuracy}')\n",
    "        model.train()\n",
    "\n",
    "    # Save the best model\n",
    "    model.load_state_dict(best_model)\n",
    "    save_model_and_parameters(model, modality_used, mask, {f\"epochs\": {epochs}, \"lr\": 0.001})\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(test_features_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    make_csv(y_pred_test, modality_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array loaded from '../radiomics features/all/radiomics_train.npy'\n",
      "Array loaded from '../radiomics features/all/radiomics_validate.npy'\n",
      "radiomic_Train_fetures (235, 400)\n",
      "radiomic_Validation_fetures (29, 400)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "radiomic_Train_fetures = load_radiomic_fetures(\"../radiomics features/all\", \"radiomics_train.npy\")\n",
    "radiomic_Validation_fetures = load_radiomic_fetures(\"../radiomics features/all\", \"radiomics_validate.npy\")\n",
    "\n",
    "print(\"radiomic_Train_fetures\",radiomic_Train_fetures.shape)\n",
    "print(\"radiomic_Validation_fetures\",radiomic_Validation_fetures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and combining features... \n",
      " local-flair_t1ce\n",
      " global-flair_t1ce\n",
      "global_train_features (236, 744) local_train_features (236, 128)\n",
      "global_validate_features (29, 744) local_validation_features (29, 128)\n",
      "combining all\n",
      "radiomics_local_global_training (235, 1272)\n",
      "radiomics_local_global_Validation (29, 1272)\n",
      "Size of training features before Stochastic Gates: (188, 1272)\n",
      "Size of validation features before Stochastic Gates: (47, 1272)\n",
      "Size of features after Stochastic Gates: (235, 392)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 8/10000 [00:00<02:12, 75.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|█████     | 5012/10000 [01:14<01:10, 70.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000, Loss: 4.6488662919230705e-10\n",
      "> Epoch 5000, Validation Loss: 250768.484375, best: 141542.359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 10000/10000 [02:32<00:00, 65.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10000, Loss: 1.0051192285883321e-09\n",
      "> Epoch 10000, Validation Loss: 236545.0625, best: 141542.359375\n",
      "Model, parameters, and Stochastic Gates mask saved successfully for modality global_flair_t1ce___local_flair_t1ce.\n",
      "CSV file '../radiomics_local_global_predictions/Stochastic Gates_feture_selection/Neural_Network_256_dim/Intersection_mask_1_2/global_flair_t1ce___local_flair_t1ce_Neural_Network.csv' created successfully.\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for modality_used_global, modality_used_local in zip(Light_GBM_global, Light_GBM_local):\n",
    "    modality_key_local = modality_used_local.split(\"_\")\n",
    "    modality_keys_list_global_features = modality_used_global.split(\"_\")\n",
    "    print(f\"\\nLoading and combining features... \\n local-{modality_used_local}\\n global-{modality_used_global}\")\n",
    "\n",
    "    local_train_features = load_and_combine_features(modality_key_local, 'train')\n",
    "    local_validation_features = load_and_combine_features(modality_key_local, 'validation')\n",
    "    \n",
    "    global_train_features, global_validate_features, train_labels = load_features(modality_used_global)\n",
    "    \n",
    "    print(\"global_train_features\",global_train_features.shape, \"local_train_features\", local_train_features.shape)\n",
    "    print(\"global_validate_features\", global_validate_features.shape, \"local_validation_features\",local_validation_features.shape)\n",
    "\n",
    "\n",
    "    local_global_training_features = np.concatenate((global_train_features, local_train_features), axis=1)\n",
    "    local_global_validation_features = np.concatenate((global_validate_features, local_validation_features), axis=1)\n",
    "    \n",
    "#   To remove the data of absent paitents from the local and global features\n",
    "    train_labels = np.delete(train_labels, 98, axis=0)\n",
    "    local_global_training_features = np.delete(local_global_training_features, 98, axis=0)\n",
    "    # local_global_validation_features = np.delete(local_global_validation_features, 26, axis=0)\n",
    "\n",
    "\n",
    "    training_all_features = np.concatenate((local_global_training_features, radiomic_Train_fetures), axis=1)\n",
    "    validation_all_features = np.concatenate((local_global_validation_features,radiomic_Validation_fetures), axis=1)\n",
    "\n",
    "    print(\"combining all\")\n",
    "    print(\"radiomics_local_global_training\",training_all_features.shape)\n",
    "    print(\"radiomics_local_global_Validation\",validation_all_features.shape)\n",
    "\n",
    "    modality_used = 'global_' + modality_used_global + '___local_' + modality_used_local\n",
    "    if selection_method == \"Stochastic Gates\":\n",
    "        train_model_with_stochastic_gates(training_all_features, validation_all_features, train_labels, modality_used)\n",
    "    elif selection_method == \"lasso\":\n",
    "        train_model(training_all_features, validation_all_features, train_labels, modality_used)\n",
    "    print(\"\\n-----------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For stocastic Gates\n",
    "\n",
    "Loading and combining features... \n",
    " local-flair_t1ce_t2\n",
    " global-flair_t1ce_t2\n",
    "global_train_features (236, 744) local_train_features (236, 192)\n",
    "global_validate_features (29, 744) local_validation_features (29, 192)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1336)\n",
    "radiomics_local_global_Validation (28, 1336)\n",
    "Size of training features before Stochastic Gates: (188, 1336)\n",
    "Size of validation features before Stochastic Gates: (47, 1336)\n",
    "Epoch: 5000: loss=123142.164062 valid_loss=159916.453125\n",
    "Epoch: 10000: loss=123142.691406 valid_loss=160539.062500\n",
    "Size of features after Stochastic Gates: (235, 501)\n",
    "Epoch 500, Loss: 1.2582521438598633\n",
    "Epoch 1000, Loss: 54.035579800605774\n",
    "CSV file '../radiomics_local_global_predictions/Stochastic Gates_feture_selection/Neural_Network/global_flair_t1ce_t2___local_flair_t1ce_t2_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and Stochastic Gates mask saved successfully for modality global_flair_t1ce_t2___local_flair_t1ce_t2.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Loading and combining features... \n",
    " local-flair_t1ce\n",
    " global-flair_t1ce_t2\n",
    "global_train_features (236, 744) local_train_features (236, 128)\n",
    "global_validate_features (29, 744) local_validation_features (29, 128)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1272)\n",
    "radiomics_local_global_Validation (28, 1272)\n",
    "Size of training features before Stochastic Gates: (188, 1272)\n",
    "Size of validation features before Stochastic Gates: (47, 1272)\n",
    "Epoch: 5000: loss=123166.786458 valid_loss=160644.562500\n",
    "Epoch: 10000: loss=123162.050781 valid_loss=161601.531250\n",
    "Size of features after Stochastic Gates: (235, 485)\n",
    "Epoch 500, Loss: 0.05665457126451656\n",
    "Epoch 1000, Loss: 81.00391387939453\n",
    "CSV file '../radiomics_local_global_predictions/Stochastic Gates_feture_selection/Neural_Network/global_flair_t1ce_t2___local_flair_t1ce_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and Stochastic Gates mask saved successfully for modality global_flair_t1ce_t2___local_flair_t1ce.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Loading and combining features... \n",
    " local-flair\n",
    " global-flair\n",
    "global_train_features (236, 744) local_train_features (236, 64)\n",
    "global_validate_features (29, 744) local_validation_features (29, 64)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1208)\n",
    "radiomics_local_global_Validation (28, 1208)\n",
    "Size of training features before Stochastic Gates: (188, 1208)\n",
    "Size of validation features before Stochastic Gates: (47, 1208)\n",
    "Epoch: 5000: loss=123177.072917 valid_loss=159584.406250\n",
    "Epoch: 10000: loss=123162.636719 valid_loss=159828.000000\n",
    "Size of features after Stochastic Gates: (235, 454)\n",
    "Epoch 500, Loss: 1.3944591656327248\n",
    "Epoch 1000, Loss: 56.555126428604126\n",
    "CSV file '../radiomics_local_global_predictions/Stochastic Gates_feture_selection/Neural_Network/global_flair___local_flair_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and Stochastic Gates mask saved successfully for modality global_flair___local_flair.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Loading and combining features... \n",
    " local-t2\n",
    " global-flair_t1ce\n",
    "global_train_features (236, 744) local_train_features (236, 64)\n",
    "global_validate_features (29, 744) local_validation_features (29, 64)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1208)\n",
    "radiomics_local_global_Validation (28, 1208)\n",
    "Size of training features before Stochastic Gates: (188, 1208)\n",
    "Size of validation features before Stochastic Gates: (47, 1208)\n",
    "Epoch: 5000: loss=123142.777344 valid_loss=157602.421875\n",
    "Epoch: 10000: loss=123144.131510 valid_loss=157510.921875\n",
    "Size of features after Stochastic Gates: (235, 498)\n",
    "Epoch 500, Loss: 0.5567352790385485\n",
    "Epoch 1000, Loss: 56.83930325508118\n",
    "CSV file '../radiomics_local_global_predictions/Stochastic Gates_feture_selection/Neural_Network/global_flair_t1ce___local_t2_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and Stochastic Gates mask saved successfully for modality global_flair_t1ce___local_t2.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Loading and combining features... \n",
    " local-flair_t1ce\n",
    " global-flair_t1ce\n",
    "global_train_features (236, 744) local_train_features (236, 128)\n",
    "global_validate_features (29, 744) local_validation_features (29, 128)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1272)\n",
    "radiomics_local_global_Validation (28, 1272)\n",
    "Size of training features before Stochastic Gates: (188, 1272)\n",
    "Size of validation features before Stochastic Gates: (47, 1272)\n",
    "Epoch: 5000: loss=123157.269531 valid_loss=159203.859375\n",
    "Epoch: 10000: loss=123160.901042 valid_loss=159248.937500\n",
    "Size of features after Stochastic Gates: (235, 522)\n",
    "Epoch 500, Loss: 48.375020027160645\n",
    "Epoch 1000, Loss: 0.5991256311535835\n",
    "CSV file '../radiomics_local_global_predictions/Stochastic Gates_feture_selection/Neural_Network/global_flair_t1ce___local_flair_t1ce_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and Stochastic Gates mask saved successfully for modality global_flair_t1ce___local_flair_t1ce.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for Lasso \n",
    "\n",
    "Loading and combining features... \n",
    " local-flair_t1ce_t2\n",
    " global-flair_t1ce_t2\n",
    "global_train_features (236, 744) local_train_features (236, 192)\n",
    "global_validate_features (29, 744) local_validation_features (29, 192)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1336)\n",
    "radiomics_local_global_Validation (28, 1336)\n",
    "Size of features before Lasso: (235, 1336)\n",
    "Size of features after Stochastic Gates: (235, 670)\n",
    "Epoch 500, Loss: 3.097682014107704\n",
    "Epoch 1000, Loss: 211.7134804725647\n",
    "CSV file '../radiomics_local_global_predictions/lasso_feture_selection/Neural_Network/global_flair_t1ce_t2___local_flair_t1ce_t2_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and lasso mask saved successfully for modality global_flair_t1ce_t2___local_flair_t1ce_t2.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Loading and combining features... \n",
    " local-flair_t1ce\n",
    " global-flair_t1ce_t2\n",
    "global_train_features (236, 744) local_train_features (236, 128)\n",
    "global_validate_features (29, 744) local_validation_features (29, 128)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1272)\n",
    "radiomics_local_global_Validation (28, 1272)\n",
    "Size of features before Lasso: (235, 1272)\n",
    "Size of features after Stochastic Gates: (235, 651)\n",
    "Epoch 500, Loss: 0.02359358873218298\n",
    "Epoch 1000, Loss: 3.981287568807602\n",
    "CSV file '../radiomics_local_global_predictions/lasso_feture_selection/Neural_Network/global_flair_t1ce_t2___local_flair_t1ce_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and lasso mask saved successfully for modality global_flair_t1ce_t2___local_flair_t1ce.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Loading and combining features... \n",
    " local-flair\n",
    " global-flair\n",
    "global_train_features (236, 744) local_train_features (236, 64)\n",
    "global_validate_features (29, 744) local_validation_features (29, 64)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1208)\n",
    "radiomics_local_global_Validation (28, 1208)\n",
    "Size of features before Lasso: (235, 1208)\n",
    "Size of features after Stochastic Gates: (235, 606)\n",
    "Epoch 500, Loss: 30.867851197719574\n",
    "Epoch 1000, Loss: 251.14953899383545\n",
    "CSV file '../radiomics_local_global_predictions/lasso_feture_selection/Neural_Network/global_flair___local_flair_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and lasso mask saved successfully for modality global_flair___local_flair.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Loading and combining features... \n",
    " local-t2\n",
    " global-flair_t1ce\n",
    "global_train_features (236, 744) local_train_features (236, 64)\n",
    "global_validate_features (29, 744) local_validation_features (29, 64)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1208)\n",
    "radiomics_local_global_Validation (28, 1208)\n",
    "Size of features before Lasso: (235, 1208)\n",
    "Size of features after Stochastic Gates: (235, 583)\n",
    "Epoch 500, Loss: 3.6403137370944023\n",
    "Epoch 1000, Loss: 1.103215642273426\n",
    "CSV file '../radiomics_local_global_predictions/lasso_feture_selection/Neural_Network/global_flair_t1ce___local_t2_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and lasso mask saved successfully for modality global_flair_t1ce___local_t2.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Loading and combining features... \n",
    " local-flair_t1ce\n",
    " global-flair_t1ce\n",
    "global_train_features (236, 744) local_train_features (236, 128)\n",
    "global_validate_features (29, 744) local_validation_features (29, 128)\n",
    "combining all\n",
    "radiomics_local_global_training (235, 1272)\n",
    "radiomics_local_global_Validation (28, 1272)\n",
    "Size of features before Lasso: (235, 1272)\n",
    "Size of features after Stochastic Gates: (235, 621)\n",
    "Epoch 500, Loss: 358.2224006652832\n",
    "Epoch 1000, Loss: 3.599237322807312\n",
    "CSV file '../radiomics_local_global_predictions/lasso_feture_selection/Neural_Network/global_flair_t1ce___local_flair_t1ce_Neural_Network.csv' created successfully.\n",
    "Model, parameters, and lasso mask saved successfully for modality global_flair_t1ce___local_flair_t1ce.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
